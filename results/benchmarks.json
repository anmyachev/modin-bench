{
    "benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, data_size, axis):\n        execute(self.df.apply(lambda df: df.sum(), axis=axis))\n\n    def setup(self, data_size, axis):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "data_size",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6314cda1081b9c6ac70187b9feae2e986fc58cc9a72da4fc0d197da29de7b05a",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, data_size, axis):\n        execute(self.df.mean(axis=axis))\n\n    def setup(self, data_size, axis):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "data_size",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "93111a13a4bd93a24c63ee05e8accc5cacbdc7d0ebfada3638db58c12937b8aa",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, data_size, axis):\n        execute(self.df.median(axis=axis))\n\n    def setup(self, data_size, axis):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "data_size",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c0c046375585f631ebc06a92f25fa07638741ba277f94fcf4d15463fc24fedf0",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, data_size, axis):\n        execute(self.df.nunique(axis=axis))\n\n    def setup(self, data_size, axis):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "data_size",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0d42b0126c0dfb20482b56097501008eb2e5e63c8de648058bc3b45da3cca12e",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, data_size, axis):\n        execute(self.df.sum(axis=axis))\n\n    def setup(self, data_size, axis):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "data_size",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e5eeadf7b618b5c1d0029a75a2ddc480355b696ff753b3fb40d5791ee1af0019",
        "warmup_time": -1
    },
    "benchmarks.TimeBinaryOp.time_binary_op": {
        "code": "class TimeBinaryOp:\n    def time_binary_op(self, data_size, binary_op, axis):\n        execute(self.op(self.df2, axis=axis))\n\n    def setup(self, data_size, binary_op, axis):\n        # shape for generate_dataframe: first - ncols, second - nrows\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[3], data_size[2], RAND_LOW, RAND_HIGH\n        )\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "benchmarks.TimeBinaryOp.time_binary_op",
        "number": 0,
        "param_names": [
            "data_size",
            "binary_op",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000, 5000, 5000)",
                "(500000, 20, 1000000, 10)"
            ],
            [
                "'mul'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c0c0bfea7db890793c0cdd71a2017b1500b015e122345df2df69e13d0f0af3fb",
        "warmup_time": -1
    },
    "benchmarks.TimeConcat.time_concat": {
        "code": "class TimeConcat:\n    def time_concat(self, data_size, how, axis):\n        if ASV_USE_IMPL == \"modin\":\n            execute(pd.concat([self.df1, self.df2], axis=axis, join=how))\n        elif ASV_USE_IMPL == \"pandas\":\n            execute(pandas.concat([self.df1, self.df2], axis=axis, join=how))\n        else:\n            raise NotImplementedError\n\n    def setup(self, data_size, how, axis):\n        # shape for generate_dataframe: first - ncols, second - nrows\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[3], data_size[2], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeConcat.time_concat",
        "number": 0,
        "param_names": [
            "data_size",
            "how",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000, 5000, 5000)",
                "(500000, 20, 1000000, 10)"
            ],
            [
                "'inner'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e51b9d5e835277f6610086acbbcfee1632b86d83a7987e10e9b041620e39b56b",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, data_size):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, data_size, ncols=1):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.groupby_columns = self.df.columns[:ncols].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "data_size"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e0243f7e1e6665ad448a0879deb0eae6ec778ca464dc914f6b795168ef153e1c",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_mean(self, data_size):\n        execute(self.df.groupby(by=self.groupby_columns).mean())\n\nclass BaseTimeGroupBy:\n    def setup(self, data_size, ncols=1):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.groupby_columns = self.df.columns[:ncols].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean",
        "number": 0,
        "param_names": [
            "data_size"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "633e985ae996fb71e28a5fbb1752ddfe277a3b6a96c990f2c603860fec37803a",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_size(self, data_size):\n        execute(self.df.groupby(by=self.groupby_columns).size())\n\nclass BaseTimeGroupBy:\n    def setup(self, data_size, ncols=1):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.groupby_columns = self.df.columns[:ncols].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size",
        "number": 0,
        "param_names": [
            "data_size"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e9972036b7bb022f63437849815fe185c1f45b7e8cb58165f7ca73bbb9583ed5",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, data_size):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, data_size, ncols=1):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.groupby_columns = self.df.columns[:ncols].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "data_size"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9c1ef1d80847ca5c97cab3597fa3d43ebd19f4f35897bde334383bc523f08fdb",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg": {
        "code": "class TimeGroupByDictionaryAggregation:\n    def time_groupby_dict_agg(self, data_size, operation_type):\n        execute(self.df.groupby(by=self.groupby_columns).agg(self.agg_dict))\n\n    def setup(self, data_size, operation_type):\n        super().setup(data_size)\n        self.cols_to_agg = self.df.columns[1:4]\n        operations = self.operations[operation_type]\n        self.agg_dict = {\n            c: operations[i % len(operations)] for i, c in enumerate(self.cols_to_agg)\n        }",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg",
        "number": 0,
        "param_names": [
            "data_size",
            "operation_type"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "'reduction'",
                "'aggregation'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a42c04248c6eb3850a3499f0dbf2edf2703e1aeb776f84aeb64dd36367b38a72",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_qc": {
        "code": "class TimeInsert:\n    def time_insert_qc(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, data_size, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_qc",
        "number": 0,
        "param_names": [
            "data_size",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2a90dd4d3e63be0acad40dd947ba11fc80429b376652696b8da66b5004c2bcb7",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_raw": {
        "code": "class TimeInsert:\n    def time_insert_raw(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item_raw)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, data_size, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_raw",
        "number": 0,
        "param_names": [
            "data_size",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "23ce4df113ef3340d09fab5aaae31b8d22db3b30348df5ff83799e98aad21d37",
        "warmup_time": -1
    },
    "benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, data_size, how, sort):\n        execute(\n            self.df1.join(\n                self.df2, on=self.df1.columns[0], how=how, lsuffix=\"left_\", sort=sort\n            )\n        )\n\n    def setup(self, data_size, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[3], data_size[2], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "data_size",
            "how",
            "sort"
        ],
        "params": [
            [
                "(5000, 5000, 5000, 5000)",
                "(500000, 20, 1000000, 10)"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "636673bc1048096364be3ba5bfad76af335dfd2ee788b3ecb2f4d434cc165c02",
        "warmup_time": -1
    },
    "benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, data_size, how, sort):\n        execute(self.df1.merge(self.df2, on=self.df1.columns[0], how=how, sort=sort))\n\n    def setup(self, data_size, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[3], data_size[2], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "data_size",
            "how",
            "sort"
        ],
        "params": [
            [
                "(5000, 5000, 5000, 5000)",
                "(125000, 15, 100000, 10)"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "08f06e9ab11ed3b1520cf53591e42a21a8c2e02b7e139a27ce6cce2a6b50489e",
        "warmup_time": -1
    },
    "benchmarks.TimeMultiColumnGroupby.time_groupby_agg_mean": {
        "code": "class TimeMultiColumnGroupby:\n    def time_groupby_agg_mean(self, data_size, ncols):\n        execute(self.df.groupby(by=self.groupby_columns).apply(lambda df: df.mean()))\n\nclass BaseTimeGroupBy:\n    def setup(self, data_size, ncols=1):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.groupby_columns = self.df.columns[:ncols].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeMultiColumnGroupby.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "data_size",
            "ncols"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(10000, 10)"
            ],
            [
                "6"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eaf9c2bfd97377fd89938b0d56a9b10e7e1cc5a7584f07203c40ef725199c5c7",
        "warmup_time": -1
    },
    "benchmarks.TimeMultiColumnGroupby.time_groupby_agg_quan": {
        "code": "class TimeMultiColumnGroupby:\n    def time_groupby_agg_quan(self, data_size, ncols):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"quantile\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, data_size, ncols=1):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.groupby_columns = self.df.columns[:ncols].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeMultiColumnGroupby.time_groupby_agg_quan",
        "number": 0,
        "param_names": [
            "data_size",
            "ncols"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(10000, 10)"
            ],
            [
                "6"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "55cf6d11d7dc3d294265e52edad0703dad30db505eba7c78d892d946f18130c3",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_qc": {
        "code": "class TimeSetItem:\n    def time_setitem_qc(self, *args, **kwargs):\n        self.df[self.loc] = self.item\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, data_size, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_qc",
        "number": 0,
        "param_names": [
            "data_size",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a07bad9e2ab768eece2959e117d93a39a09a73a3357c398f3748eff6eea16dd5",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_raw": {
        "code": "class TimeSetItem:\n    def time_setitem_raw(self, *args, **kwargs):\n        self.df[self.loc] = self.item_raw\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, data_size, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_raw",
        "number": 0,
        "param_names": [
            "data_size",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ddce9ffcb112bece4426fe804e07ca30d08a83580fd4f9366fb8ed87c10de67f",
        "warmup_time": -1
    },
    "benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, data_size, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, data_size, columns_number, ascending_list):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", data_size[1], data_size[0], RAND_LOW, RAND_HIGH\n        )\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "data_size",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1",
                "2",
                "10",
                "100"
            ],
            [
                "False",
                "True"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4825067949244f1abe1998dbe710e3014052245c403746003cae3d1b89b51bb3",
        "warmup_time": -1
    },
    "version": 2
}